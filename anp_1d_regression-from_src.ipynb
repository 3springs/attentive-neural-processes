{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T05:13:40.924406Z",
     "start_time": "2020-02-01T05:13:39.398555Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wassname/.pyenv/versions/3.7.2/envs/jup3.7.2/lib/python3.7/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['plt']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import collections\n",
    "from tqdm.auto import tqdm\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import math\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T05:13:41.307694Z",
     "start_time": "2020-02-01T05:13:40.932281Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T05:13:41.335249Z",
     "start_time": "2020-02-01T05:13:41.319485Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.data.gp_curves import GPCurvesReader\n",
    "from src.models.model import LatentModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T05:13:41.354190Z",
     "start_time": "2020-02-01T05:13:41.338986Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_seed(n=42):\n",
    "    np.random.seed(n)\n",
    "    torch.manual_seed(n)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T05:13:41.386138Z",
     "start_time": "2020-02-01T05:13:41.363884Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_functions(target_x, target_y, context_x, context_y, pred_y, std):\n",
    "    \"\"\"Plots the predicted mean and variance and the context points.\n",
    "  \n",
    "  Args: \n",
    "    target_x: An array of shape [B,num_targets,1] that contains the\n",
    "        x values of the target points.\n",
    "    target_y: An array of shape [B,num_targets,1] that contains the\n",
    "        y values of the target points.\n",
    "    context_x: An array of shape [B,num_contexts,1] that contains \n",
    "        the x values of the context points.\n",
    "    context_y: An array of shape [B,num_contexts,1] that contains \n",
    "        the y values of the context points.\n",
    "    pred_y: An array of shape [B,num_targets,1] that contains the\n",
    "        predicted means of the y values at the target points in target_x.\n",
    "    std: An array of shape [B,num_targets,1] that contains the\n",
    "        predicted std dev of the y values at the target points in target_x.\n",
    "      \"\"\"\n",
    "    # Plot everything\n",
    "    plt.plot(target_x[0], pred_y[0], 'b', linewidth=2)\n",
    "    plt.plot(target_x[0], target_y[0], 'k:', linewidth=2)\n",
    "    plt.plot(context_x[0], context_y[0], 'ko', markersize=10)\n",
    "    plt.fill_between(\n",
    "          target_x[0, :, 0],\n",
    "          pred_y[0, :, 0] - std[0, :, 0],\n",
    "          pred_y[0, :, 0] + std[0, :, 0],\n",
    "          alpha=0.2,\n",
    "          facecolor='#65c9f7',\n",
    "          interpolate=True)\n",
    "\n",
    "    # Make the plot pretty\n",
    "    plt.yticks([-2, 0, 2], fontsize=16)\n",
    "    plt.xticks([-2, 0, 2], fontsize=16)\n",
    "    plt.ylim([-2, 2])\n",
    "    plt.grid('off')\n",
    "    ax = plt.gca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T05:13:41.422421Z",
     "start_time": "2020-02-01T05:13:41.388688Z"
    }
   },
   "outputs": [],
   "source": [
    "def test(model, dataset_test, writer=None, plot=False, global_step=None):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        data_test = dataset_test.generate_curves()\n",
    "\n",
    "        (context_x, context_y), target_x = data_test.query\n",
    "        target_y = data_test.target_y\n",
    "\n",
    "        context_x = context_x.cuda()\n",
    "        context_y = context_y.cuda()\n",
    "        target_x = target_x.cuda()\n",
    "        target_y = target_y.cuda()\n",
    "\n",
    "        y_pred, kl, loss, mse_loss, y_std = model(context_x, context_y, target_x, target_y)\n",
    "\n",
    "        if writer is not None:\n",
    "            writer.add_scalar('val/loss', loss, global_step=global_step)\n",
    "            writer.add_scalar('val/y_std', y_std.mean(), global_step=global_step)\n",
    "            writer.add_scalar('val/mse_loss', mse_loss, global_step=global_step)\n",
    "            writer.add_scalar('val/kl', kl.mean(), global_step=global_step)\n",
    "        \n",
    "        if plot:\n",
    "            fig = plt.figure()\n",
    "            plt.title(f\"Iter {global_step}\")            \n",
    "            plot_functions(target_x.detach().cpu().numpy(),\n",
    "                           target_y.detach().cpu().numpy(),\n",
    "                           context_x.detach().cpu().numpy(),\n",
    "                           context_y.detach().cpu().numpy(),\n",
    "                           y_pred.detach().cpu().numpy(),\n",
    "                           y_std.detach().cpu().numpy())\n",
    "            \n",
    "            writer.add_figure('test', fig, global_step=global_step, close=False)\n",
    "            plt.show()\n",
    "            \n",
    "    return y_pred, kl, loss, y_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T05:13:41.451774Z",
     "start_time": "2020-02-01T05:13:41.435188Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "MAX_CONTEXT_POINTS = 50 \n",
    "random_kernel_parameters=True \n",
    "\n",
    "dataset_train = GPCurvesReader(\n",
    "    batch_size=16, max_num_context=MAX_CONTEXT_POINTS, random_kernel_parameters=random_kernel_parameters)\n",
    "\n",
    "dataset_test = GPCurvesReader(\n",
    "    batch_size=1, max_num_context=MAX_CONTEXT_POINTS, testing=True, random_kernel_parameters=random_kernel_parameters)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replicate ANP paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T05:13:41.471810Z",
     "start_time": "2020-02-01T05:13:41.457847Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 100000\n",
    "PLOT_AFTER = 10000\n",
    "PRINT_AFTER = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T05:14:09.036471Z",
     "start_time": "2020-02-01T05:13:41.481257Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs/Feb01_13-13-41_mjcdesktop-anp_1d_reg\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96123dbd631e462a894b9a594f729f73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=100000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 0 loss= 0.7616 val_loss= 1.174\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-6bce5c3f52ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     y_pred, kl, loss, mse_loss, y_std = model(context_x, context_y, target_x,\n\u001b[0;32m---> 33\u001b[0;31m                                               target_y)\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/envs/jup3.7.2/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/wassname/Storage5/projects2/3ST/attentive-neural-processes/src/models/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, context_x, context_y, target_x, target_y)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mnum_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mdist_prior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_var_prior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_latent_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtarget_y\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/envs/jup3.7.2/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/wassname/Storage5/projects2/3ST/attentive-neural-processes/src/models/modules.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encoder\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m             \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;31m# Aggregator: take the mean over all points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "writer = SummaryWriter(comment='-anp_1d_reg')\n",
    "print(writer.logdir)\n",
    "\n",
    "hparams = dict(\n",
    "    x_dim=1,\n",
    "    y_dim=1,\n",
    "    hidden_dim=128,\n",
    "    latent_dim=128,\n",
    "    latent_enc_self_attn_type=\"multihead\",\n",
    "    det_enc_self_attn_type=\"multihead\",\n",
    "    det_enc_cross_attn_type=\"multihead\")\n",
    "model = LatentModel(**hparams).cuda()\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "for n_iter in tqdm(range(epochs)):\n",
    "    model.train()\n",
    "\n",
    "    data_train = dataset_train.generate_curves()\n",
    "\n",
    "    (context_x, context_y), target_x = data_train.query\n",
    "    target_y = data_train.target_y\n",
    "\n",
    "    context_x = context_x.cuda()\n",
    "    context_y = context_y.cuda()\n",
    "    target_x = target_x.cuda()\n",
    "    target_y = target_y.cuda()\n",
    "\n",
    "    optim.zero_grad()\n",
    "    y_pred, kl, loss, mse_loss, y_std = model(context_x, context_y, target_x,\n",
    "                                              target_y)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "    writer.add_scalar('train/loss', loss, n_iter)\n",
    "    writer.add_scalar('train/mse_loss', mse_loss, n_iter)\n",
    "    writer.add_scalar('train/y_std', y_std.mean(), n_iter)\n",
    "    writer.add_scalar('train/kl', kl.mean(), n_iter)\n",
    "\n",
    "    if n_iter % PRINT_AFTER == 0:\n",
    "        y_pred, kl, val_loss, y_std = test(\n",
    "            model, dataset_test, writer, plot=False, global_step=n_iter)\n",
    "        print(\n",
    "            f\"train: {n_iter} loss={loss.item(): 4.4g} val_loss={val_loss.item(): 4.4g}\"\n",
    "        )\n",
    "\n",
    "    if n_iter % PLOT_AFTER == 0:\n",
    "        test(model, dataset_test, writer, plot=True, global_step=n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T05:14:09.043813Z",
     "start_time": "2020-02-01T05:13:39.400Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    set_seed(i)\n",
    "    test(model, dataset_test, writer, plot=True, global_step=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T05:14:09.045314Z",
     "start_time": "2020-02-01T05:13:39.400Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Final validation\n",
    "loss = torch.stack([test(model, dataset_test)[2] for _ in tqdm(range(100))]).mean().cpu()\n",
    "print('val loss (n=100)', loss)\n",
    "writer.add_hparams(hparams, dict(val_loss=loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T03:26:03.797075Z",
     "start_time": "2020-02-01T03:19:32.800Z"
    }
   },
   "source": [
    "## Improved\n",
    "\n",
    "These have no been extensively tested:\n",
    "\n",
    "- use torches ~50% faster multiheaded attention\n",
    "- calc loss in log domain for stability (and untested changes to clipping)\n",
    "- dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T04:20:15.678601Z",
     "start_time": "2020-02-01T04:20:15.671286Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T05:14:09.046831Z",
     "start_time": "2020-02-01T05:13:39.400Z"
    }
   },
   "outputs": [],
   "source": [
    "writer = SummaryWriter(comment='-anp_1d_impr')\n",
    "print(writer.logdir)\n",
    "                 \n",
    "hparams = dict(\n",
    "    x_dim=1,\n",
    "    y_dim=1,\n",
    "    hidden_dim=128,\n",
    "    latent_dim=128,\n",
    "    latent_enc_self_attn_type=\"ptmultihead\",\n",
    "    det_enc_self_attn_type=\"ptmultihead\",\n",
    "    det_enc_cross_attn_type=\"ptmultihead\",\n",
    "    use_lvar=True,\n",
    "    use_self_attn=True,\n",
    "#     attention_dropout=0.3,\n",
    "    dropout=0.3,\n",
    "#     batchnorm=True,\n",
    ")\n",
    "model = LatentModel(**hparams).cuda()\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "for n_iter in tqdm(range(epochs)):\n",
    "    model.train()\n",
    "\n",
    "    data_train = dataset_train.generate_curves()\n",
    "\n",
    "    (context_x, context_y), target_x = data_train.query\n",
    "    target_y = data_train.target_y\n",
    "\n",
    "    context_x = context_x.cuda()\n",
    "    context_y = context_y.cuda()\n",
    "    target_x = target_x.cuda()\n",
    "    target_y = target_y.cuda()\n",
    "\n",
    "    optim.zero_grad()\n",
    "    y_pred, kl, loss, mse_loss, y_std = model(context_x, context_y, target_x,\n",
    "                                              target_y)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "    writer.add_scalar('train/loss', loss, n_iter)\n",
    "    writer.add_scalar('train/mse_loss', mse_loss, n_iter)\n",
    "    writer.add_scalar('train/y_std', y_std.mean(), n_iter)\n",
    "    writer.add_scalar('train/kl', kl.mean(), n_iter)\n",
    "\n",
    "    if n_iter % PRINT_AFTER == 0:\n",
    "        y_pred, kl, val_loss, y_std = test(\n",
    "            model, dataset_test, writer, plot=False, global_step=n_iter)\n",
    "        print(\n",
    "            f\"train: {n_iter} loss={loss.item(): 4.4g} val_loss={val_loss.item(): 4.4g}\"\n",
    "        )\n",
    "\n",
    "    if n_iter % PLOT_AFTER == 0:\n",
    "        test(model, dataset_test, writer, plot=True, global_step=n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T05:14:09.048422Z",
     "start_time": "2020-02-01T05:13:39.400Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    set_seed(i)\n",
    "    test(model, dataset_test, writer, plot=True, global_step=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T05:14:09.058258Z",
     "start_time": "2020-02-01T05:13:39.400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Final validation\n",
    "loss = torch.stack([test(model, dataset_test)[2] for _ in tqdm(range(100))]).mean().cpu()\n",
    "print('val loss (n=100)', loss)\n",
    "writer.add_hparams(hparams, dict(val_loss=loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T05:14:09.062203Z",
     "start_time": "2020-02-01T05:13:39.500Z"
    }
   },
   "outputs": [],
   "source": [
    "(hparams, dict(val_loss=loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jup3.7.2",
   "language": "python",
   "name": "jup3.7.2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
