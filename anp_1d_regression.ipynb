{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T03:19:32.799666Z",
     "start_time": "2020-02-01T03:19:32.787679Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import collections\n",
    "from tqdm.auto import tqdm\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import math\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T03:19:32.814367Z",
     "start_time": "2020-02-01T03:19:32.804007Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T02:13:20.324359Z",
     "start_time": "2020-02-01T02:13:20.314382Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T03:19:32.863577Z",
     "start_time": "2020-02-01T03:19:32.817900Z"
    }
   },
   "outputs": [],
   "source": [
    "# The (A)NP takes as input a `NPRegressionDescription` namedtuple with fields:\n",
    "#   `query`: a tuple containing ((context_x, context_y), target_x)\n",
    "#   `target_y`: a tensor containing the ground truth for the targets to be\n",
    "#     predicted\n",
    "#   `num_total_points`: A vector containing a scalar that describes the total\n",
    "#     number of datapoints used (context + target)\n",
    "#   `num_context_points`: A vector containing a scalar that describes the number\n",
    "#     of datapoints used as context\n",
    "# The GPCurvesReader returns the newly sampled data in this format at each\n",
    "# iteration\n",
    "\n",
    "NPRegressionDescription = collections.namedtuple(\n",
    "    \"NPRegressionDescription\",\n",
    "    (\"query\", \"target_y\", \"num_total_points\", \"num_context_points\"))\n",
    "\n",
    "\n",
    "class GPCurvesReader(object):\n",
    "    \"\"\"Generates curves using a Gaussian Process (GP).\n",
    "\n",
    "  Supports vector inputs (x) and vector outputs (y). Kernel is\n",
    "  mean-squared exponential, using the x-value l2 coordinate distance scaled by\n",
    "  some factor chosen randomly in a range. Outputs are independent gaussian\n",
    "  processes.\n",
    "      \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "               batch_size,\n",
    "               max_num_context,\n",
    "               x_size=1,\n",
    "               y_size=1,\n",
    "               l1_scale=0.6,\n",
    "               sigma_scale=1.0,\n",
    "               random_kernel_parameters=True,\n",
    "               testing=False):\n",
    "        \"\"\"Creates a regression dataset of functions sampled from a GP.\n",
    "\n",
    "    Args:\n",
    "      batch_size: An integer.\n",
    "      max_num_context: The max number of observations in the context.\n",
    "      x_size: Integer >= 1 for length of \"x values\" vector.\n",
    "      y_size: Integer >= 1 for length of \"y values\" vector.\n",
    "      l1_scale: Float; typical scale for kernel distance function.\n",
    "      sigma_scale: Float; typical scale for variance.\n",
    "      random_kernel_parameters: If `True`, the kernel parameters (l1 and sigma) \n",
    "          will be sampled uniformly within [0.1, l1_scale] and [0.1, sigma_scale].\n",
    "      testing: Boolean that indicates whether we are testing. If so there are\n",
    "          more targets for visualization.\n",
    "        \"\"\"\n",
    "        self._batch_size = batch_size\n",
    "        self._max_num_context = max_num_context\n",
    "        self._x_size = x_size\n",
    "        self._y_size = y_size\n",
    "        self._l1_scale = l1_scale\n",
    "        self._sigma_scale = sigma_scale\n",
    "        self._random_kernel_parameters = random_kernel_parameters\n",
    "        self._testing = testing\n",
    "\n",
    "    def _gaussian_kernel(self, xdata, l1, sigma_f, sigma_noise=2e-2):\n",
    "        \"\"\"Applies the Gaussian kernel to generate curve data.\n",
    "\n",
    "    Args:\n",
    "      xdata: Tensor of shape [B, num_total_points, x_size] with\n",
    "          the values of the x-axis data.\n",
    "      l1: Tensor of shape [B, y_size, x_size], the scale\n",
    "          parameter of the Gaussian kernel.\n",
    "      sigma_f: Tensor of shape [B, y_size], the magnitude\n",
    "          of the std.\n",
    "      sigma_noise: Float, std of the noise that we add for stability.\n",
    "\n",
    "    Returns:\n",
    "      The kernel, a float tensor of shape\n",
    "      [B, y_size, num_total_points, num_total_points].\n",
    "        \"\"\"\n",
    "        num_total_points = xdata.shape[1]\n",
    "\n",
    "    # Expand and take the difference\n",
    "        xdata1 = xdata.unsqueeze(1)  # [B, 1, num_total_points, x_size]\n",
    "        xdata2 = xdata.unsqueeze(2)  # [B, num_total_points, 1, x_size]\n",
    "        diff = xdata1 - xdata2  # [B, num_total_points, num_total_points, x_size]\n",
    "\n",
    "    # [B, y_size, num_total_points, num_total_points, x_size]\n",
    "        norm = (diff[:, None, :, :, :] / l1[:, :, None, None, :])**2\n",
    "\n",
    "        norm = torch.sum(norm, -1)  # [B, data_size, num_total_points, num_total_points]\n",
    "\n",
    "    # [B, y_size, num_total_points, num_total_points]\n",
    "        kernel = ((sigma_f)**2)[:, :, None, None] * torch.exp(-0.5 * norm)\n",
    "\n",
    "    # Add some noise to the diagonal to make the cholesky work.\n",
    "        kernel += (sigma_noise**2) * torch.eye(num_total_points)\n",
    "\n",
    "        return kernel\n",
    "\n",
    "    def generate_curves(self):\n",
    "        \"\"\"Builds the op delivering the data.\n",
    "\n",
    "    Generated functions are `float32` with x values between -2 and 2.\n",
    "    \n",
    "    Returns:\n",
    "      A `CNPRegressionDescription` namedtuple.\n",
    "        \"\"\"\n",
    "        num_context = int(np.random.rand()*(self._max_num_context - 3) + 3)\n",
    "    # If we are testing we want to have more targets and have them evenly\n",
    "    # distributed in order to plot the function.\n",
    "        if self._testing:\n",
    "            num_target = 400\n",
    "            num_total_points = num_target\n",
    "            x_values = torch.arange(-2, 2, 1.0/100).unsqueeze(0).repeat(self._batch_size, 1)\n",
    "            x_values = x_values.unsqueeze(-1)\n",
    "    # During training the number of target points and their x-positions are\n",
    "    # selected at random\n",
    "        else:\n",
    "            num_target = int(np.random.rand()*(self._max_num_context - num_context))\n",
    "            num_total_points = num_context + num_target\n",
    "            x_values = torch.rand((self._batch_size, num_total_points, self._x_size))*4 - 2\n",
    "            \n",
    "\n",
    "    # Set kernel parameters\n",
    "    # Either choose a set of random parameters for the mini-batch\n",
    "        if self._random_kernel_parameters:\n",
    "            l1 = torch.rand((self._batch_size, self._y_size, self._x_size))*(self._l1_scale - 0.1) + 0.1\n",
    "            sigma_f = torch.rand((self._batch_size, self._y_size))*(self._sigma_scale - 0.1) + 0.1\n",
    "            \n",
    "    # Or use the same fixed parameters for all mini-batches\n",
    "        else:\n",
    "            l1 = torch.ones((self._batch_size, self._y_size, self._x_size))*self._l1_scale\n",
    "            sigma_f = torch.ones((self._batch_size, self._y_size))*self._sigma_scale\n",
    "\n",
    "    # Pass the x_values through the Gaussian kernel\n",
    "    # [batch_size, y_size, num_total_points, num_total_points]\n",
    "        kernel = self._gaussian_kernel(x_values, l1, sigma_f)\n",
    "\n",
    "    # Calculate Cholesky, using double precision for better stability:\n",
    "        cholesky = torch.cholesky(kernel)\n",
    "\n",
    "    # Sample a curve\n",
    "    # [batch_size, y_size, num_total_points, 1]\n",
    "        y_values = torch.matmul(cholesky, torch.randn((self._batch_size, self._y_size, num_total_points, 1)))\n",
    "\n",
    "    # [batch_size, num_total_points, y_size]\n",
    "        y_values = y_values.squeeze(3)\n",
    "        y_values = y_values.permute(0, 2, 1)\n",
    "\n",
    "        if self._testing:\n",
    "      # Select the targets\n",
    "            target_x = x_values\n",
    "            target_y = y_values\n",
    "\n",
    "      # Select the observations\n",
    "            idx = torch.randperm(num_target)\n",
    "            context_x = x_values[:, idx[:num_context]]\n",
    "            context_y = y_values[:, idx[:num_context]]\n",
    "\n",
    "        else:\n",
    "      # Select the targets which will consist of the context points as well as\n",
    "      # some new target points\n",
    "            target_x = x_values[:, :num_target + num_context, :]\n",
    "            target_y = y_values[:, :num_target + num_context, :]\n",
    "\n",
    "      # Select the observations\n",
    "            context_x = x_values[:, :num_context, :]\n",
    "            context_y = y_values[:, :num_context, :]\n",
    "\n",
    "        query = ((context_x, context_y), target_x)\n",
    "\n",
    "        return NPRegressionDescription(\n",
    "        query=query,\n",
    "        target_y=target_y,\n",
    "        num_total_points=target_x.shape[1],\n",
    "        num_context_points=num_context)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T03:19:32.895332Z",
     "start_time": "2020-02-01T03:19:32.868161Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class NPBlockRelu2d(nn.Module):\n",
    "    \"\"\"Block for Neural Processes.\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, dropout=0, norm=False, bias=False):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_channels, out_channels, bias=bias)\n",
    "        self.act = nn.ReLU()\n",
    "        self.dropout = nn.Dropout2d(dropout)\n",
    "        self.norm = nn.BatchNorm2d(out_channels) if norm else False\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x.shape is (Batch, Sequence, Channels)\n",
    "        # We pass a linear over it which operates on the Channels\n",
    "        x = self.act(self.linear(x))\n",
    "\n",
    "        # Now we want to apply batchnorm and dropout to the channels. So we put it in shape\n",
    "        # (Batch, Channels, Sequence, None) so we can use Dropout2d\n",
    "        x = x.permute(0, 2, 1)[:, :, :, None]\n",
    "\n",
    "        if self.norm:\n",
    "            x = self.norm(x)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "        return x[:, :, :, 0].permute(0, 2, 1)\n",
    "\n",
    "\n",
    "class BatchMLP(nn.Module):\n",
    "    \"\"\"Apply MLP to the final axis of a 3D tensor (reusing already defined MLPs).\n",
    "\n",
    "    Args:\n",
    "        input: input tensor of shape [B,n,d_in].\n",
    "        output_sizes: An iterable containing the output sizes of the MLP as defined \n",
    "            in `basic.Linear`.\n",
    "    Returns:\n",
    "        tensor of shape [B,n,d_out] where d_out=output_size\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, output_size, num_layers=2, dropout=0, norm=False):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        \n",
    "        self.initial = NPBlockRelu2d(input_size, output_size, dropout=dropout, norm=norm)\n",
    "        self.encoder = nn.Sequential(* [\n",
    "            NPBlockRelu2d(output_size, output_size, dropout=dropout, norm=norm) for _ in range(num_layers - 2)\n",
    "        ])\n",
    "        self.final = nn.Linear(output_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.initial(x)\n",
    "        x = self.encoder(x)\n",
    "        return self.final(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T03:10:39.791917Z",
     "start_time": "2020-02-01T03:10:39.775892Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T03:19:32.954104Z",
     "start_time": "2020-02-01T03:19:32.902132Z"
    }
   },
   "outputs": [],
   "source": [
    "class AttnLinear(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_channels, out_channels, bias=False)\n",
    "        torch.nn.init.normal_(self.linear.weight, std=in_channels**-0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_dim, attention_type, attention_layers=2, n_heads=8, x_dim=1, rep='mlp', dropout=0):\n",
    "        super().__init__()\n",
    "        self._rep = rep\n",
    "        \n",
    "        if self._rep == 'mlp':\n",
    "            self.batch_mlp_k = BatchMLP(x_dim, hidden_dim, attention_layers, dropout=dropout)\n",
    "            self.batch_mlp_q = BatchMLP(x_dim, hidden_dim, attention_layers, dropout=dropout)\n",
    "\n",
    "        if attention_type == \"uniform\":\n",
    "            self._attention_func = self._uniform_attention\n",
    "        elif attention_type == \"laplace\":\n",
    "            self._attention_func = self._laplace_attention\n",
    "        elif attention_type == \"dot\":\n",
    "            self._attention_func = self._dot_attention\n",
    "        elif attention_type == \"multihead\":\n",
    "            self._W_k = nn.ModuleList(\n",
    "                [AttnLinear(hidden_dim, hidden_dim) for _ in range(n_heads)])\n",
    "            self._W_v = nn.ModuleList(\n",
    "                [AttnLinear(hidden_dim, hidden_dim) for _ in range(n_heads)])\n",
    "            self._W_q = nn.ModuleList(\n",
    "                [AttnLinear(hidden_dim, hidden_dim) for _ in range(n_heads)])\n",
    "            self._W = AttnLinear(n_heads * hidden_dim, hidden_dim)\n",
    "            self._attention_func = self._multihead_attention\n",
    "            self.n_heads = n_heads\n",
    "        elif attention_type ==\"ptmultihead\":\n",
    "            self._attention_func = torch.nn.MultiheadAttention(\n",
    "                hidden_dim, n_heads, bias=False, dropout=dropout\n",
    "            )\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def forward(self, k, v, q):\n",
    "        if self._rep == 'mlp':\n",
    "            k = self.batch_mlp_k(k)\n",
    "            q = self.batch_mlp_q(q)\n",
    "        rep = self._attention_func(k, v, q)\n",
    "        return rep\n",
    "\n",
    "    def _uniform_attention(self, k, v, q):\n",
    "        total_points = q.shape[1]\n",
    "        rep = torch.mean(v, dim=1, keepdim=True)\n",
    "        rep = rep.repeat(1, total_points, 1)\n",
    "        return rep\n",
    "\n",
    "    def _laplace_attention(self, k, v, q, scale=0.5):\n",
    "        k_ = k.unsqueeze(1)\n",
    "        v_ = v.unsqueeze(2)\n",
    "        unnorm_weights = torch.abs((k_ - v_) * scale)\n",
    "        unnorm_weights = unnorm_weights.sum(dim=-1)\n",
    "        weights = torch.softmax(unnorm_weights, dim=-1)\n",
    "        rep = torch.einsum('bik,bkj->bij', weights, v)\n",
    "        return rep\n",
    "\n",
    "    def _dot_attention(self, k, v, q):\n",
    "        scale = q.shape[-1]**0.5\n",
    "        unnorm_weights = torch.einsum('bjk,bik->bij', k, q) / scale\n",
    "        weights = torch.softmax(unnorm_weights, dim=-1)\n",
    "\n",
    "        rep = torch.einsum('bik,bkj->bij', weights, v)\n",
    "        return rep\n",
    "\n",
    "    def _multihead_attention(self, k, v, q):\n",
    "        outs = []\n",
    "        for i in range(self.n_heads):\n",
    "            k_ = self._W_k[i](k)\n",
    "            v_ = self._W_v[i](v)\n",
    "            q_ = self._W_q[i](q)\n",
    "            out = self._dot_attention(k_, v_, q_)\n",
    "            outs.append(out)\n",
    "        outs = torch.stack(outs, dim=-1)\n",
    "        outs = outs.view(outs.shape[0], outs.shape[1], -1)\n",
    "        rep = self._W(outs)\n",
    "        return rep\n",
    "    \n",
    "    def _pytorch_multihead_attention(self, k, v, q):\n",
    "        # Pytorch multiheaded attention takes inputs if diff order and permutation\n",
    "        q = q.permute(1, 0, 2)\n",
    "        k = k.permute(1, 0, 2)\n",
    "        v = v.permute(1, 0, 2)\n",
    "        o = self._attention_func(q, k, v)[0]\n",
    "        return o.permute(1, 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T03:19:32.981923Z",
     "start_time": "2020-02-01T03:19:32.957280Z"
    }
   },
   "outputs": [],
   "source": [
    "class LatentEncoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_dim,\n",
    "                 hidden_dim=32,\n",
    "                 latent_dim=32,\n",
    "                 self_attention_type=\"dot\",\n",
    "                 n_encoder_layers=3,\n",
    "                 min_std=0.01,\n",
    "                 use_lvar=False,\n",
    "                 use_self_attn=False,      \n",
    "                 attention_layers=2,\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self._input_layer = nn.Linear(input_dim, hidden_dim)\n",
    "        self._encoder = nn.ModuleList([\n",
    "            nn.Linear(hidden_dim, hidden_dim) for _ in range(n_encoder_layers)\n",
    "        ])\n",
    "        if use_self_attn:\n",
    "            self._self_attention = Attention(hidden_dim, self_attention_type, attention_layers, rep='identity')\n",
    "        self._penultimate_layer = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self._mean = nn.Linear(hidden_dim, latent_dim)\n",
    "        self._log_var = nn.Linear(hidden_dim, latent_dim)\n",
    "        self._min_std = min_std\n",
    "        self._use_lvar = use_lvar\n",
    "        self._use_self_attn = use_self_attn\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        encoder_input = torch.cat([x, y], dim=-1)\n",
    "\n",
    "        # Pass final axis through MLP\n",
    "        encoded = self._input_layer(encoder_input)\n",
    "        for layer in self._encoder:\n",
    "            encoded = torch.relu(layer(encoded))\n",
    "\n",
    "        # Aggregator: take the mean over all points\n",
    "        if self._use_self_attn:\n",
    "            attention_output = self._self_attention(encoded, encoded, encoded)\n",
    "            mean_repr = attention_output.mean(dim=1)\n",
    "        else:\n",
    "            mean_repr = encoded.mean(dim=1)\n",
    "\n",
    "        # Have further MLP layers that map to the parameters of the Gaussian latent\n",
    "        mean_repr = torch.relu(self._penultimate_layer(mean_repr))\n",
    "\n",
    "        # Then apply further linear layers to output latent mu and log sigma\n",
    "        mean = self._mean(mean_repr)\n",
    "        log_var = self._log_var(mean_repr)\n",
    "\n",
    "        # Clip it in the log domain, so it can only approach self.min_std, this helps avoid mode collapase\n",
    "        # 2 ways, a better but untested way using the more stable log domain, and the way from the deepmind repo\n",
    "        if self._use_lvar:\n",
    "            log_var = log_var + math.log(self._min_std)\n",
    "            sigma = torch.exp(0.5 * log_var)\n",
    "        else:\n",
    "            sigma = self._min_std + (1 - self._min_std) * torch.sigmoid(log_var * 0.5)\n",
    "        dist = torch.distributions.Normal(mean, sigma)\n",
    "        return dist, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T03:19:32.998565Z",
     "start_time": "2020-02-01T03:19:32.984808Z"
    }
   },
   "outputs": [],
   "source": [
    "class DeterministicEncoder(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_dim,\n",
    "            x_dim,\n",
    "            hidden_dim=32,\n",
    "            n_d_encoder_layers=3,\n",
    "            self_attention_type=\"dot\",\n",
    "            cross_attention_type=\"dot\",\n",
    "            use_self_attn=False,\n",
    "            attention_layers=2, ):\n",
    "        super().__init__()\n",
    "        self._use_self_attn = use_self_attn\n",
    "        self._input_layer = nn.Linear(input_dim, hidden_dim)\n",
    "        self._d_encoder = nn.ModuleList([\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "            for _ in range(n_d_encoder_layers)\n",
    "        ])\n",
    "        if use_self_attn:\n",
    "            self._self_attention = Attention(\n",
    "                hidden_dim,\n",
    "                self_attention_type,\n",
    "                attention_layers,\n",
    "                rep='identity')\n",
    "        self._cross_attention = Attention(\n",
    "            hidden_dim,\n",
    "            cross_attention_type,\n",
    "            x_dim=x_dim,\n",
    "            attention_layers=attention_layers)\n",
    "\n",
    "    def forward(self, context_x, context_y, target_x):\n",
    "        # Concatenate x and y along the filter axes\n",
    "        d_encoder_input = torch.cat([context_x, context_y], dim=-1)\n",
    "\n",
    "        # Pass final axis through MLP\n",
    "        d_encoded = self._input_layer(d_encoder_input)\n",
    "        for layer in self._d_encoder:\n",
    "            d_encoded = torch.relu(layer(d_encoded))\n",
    "\n",
    "        if self._use_self_attn:\n",
    "            d_encoded = self._self_attention(d_encoded, d_encoded, d_encoded)\n",
    "\n",
    "        # Apply attention\n",
    "        h = self._cross_attention(context_x, d_encoded, target_x)\n",
    "\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T03:19:33.019374Z",
     "start_time": "2020-02-01T03:19:33.002371Z"
    }
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 x_dim,\n",
    "                 y_dim,\n",
    "                 hidden_dim=32,\n",
    "                 latent_dim=32,\n",
    "                 n_decoder_layers=3,\n",
    "                 use_deterministic_path=True,\n",
    "                 min_std=0.01,\n",
    "                 use_lvar=False):\n",
    "        super(Decoder, self).__init__()\n",
    "        self._target_transform = nn.Linear(x_dim, hidden_dim)\n",
    "        if use_deterministic_path:\n",
    "            hidden_dim_2 = 2 * hidden_dim + latent_dim\n",
    "        else:\n",
    "            hidden_dim_2 = hidden_dim + latent_dim\n",
    "        self._decoder = nn.ModuleList([\n",
    "            nn.Linear(hidden_dim_2, hidden_dim_2)\n",
    "            for _ in range(n_decoder_layers)\n",
    "        ])\n",
    "        self._mean = nn.Linear(hidden_dim_2, y_dim)\n",
    "        self._std = nn.Linear(hidden_dim_2, y_dim)\n",
    "        self._use_deterministic_path = use_deterministic_path\n",
    "        self._min_std = min_std\n",
    "        self._use_lvar = use_lvar\n",
    "\n",
    "    def forward(self, r, z, target_x):\n",
    "        # concatenate target_x and representation\n",
    "        x = self._target_transform(target_x)\n",
    "\n",
    "        if self._use_deterministic_path:\n",
    "            z = torch.cat([r, z], dim=-1)\n",
    "\n",
    "        representation = torch.cat([z, x], dim=-1)\n",
    "        \n",
    "        # Pass final axis through MLP\n",
    "        for layer in self._decoder:\n",
    "            representation = torch.relu(layer(representation))\n",
    "\n",
    "        # Get the mean and the variance\n",
    "        mean = self._mean(representation)\n",
    "        log_sigma = self._std(representation)\n",
    "\n",
    "        # Bound the variance\n",
    "        if self._use_lvar:\n",
    "            log_sigma = log_sigma + math.log(self._min_std)\n",
    "            sigma = torch.exp(log_sigma)\n",
    "        else:\n",
    "            sigma = self._min_std + (1 - self._min_std) * F.softplus(log_sigma)\n",
    "\n",
    "        dist = torch.distributions.Normal(mean, sigma)\n",
    "        return dist, log_sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T03:19:33.033796Z",
     "start_time": "2020-02-01T03:19:33.021744Z"
    }
   },
   "outputs": [],
   "source": [
    "def kl_loss_var(prior_mu, log_var_prior, post_mu, log_var_post):\n",
    "    \"\"\"\n",
    "    Analytical KLD for two gaussians, taking in log_variance instead of scale ( given variance=scale**2) for more stable gradients\n",
    "    \n",
    "    For version using scale see https://github.com/pytorch/pytorch/blob/master/torch/distributions/kl.py#L398\n",
    "    \"\"\"\n",
    "\n",
    "    var_ratio_log = log_var_post - log_var_prior\n",
    "    kl_div = (\n",
    "        (var_ratio_log.exp() +\n",
    "         (post_mu - prior_mu)**2) / log_var_prior.exp() - 1.0 - var_ratio_log)\n",
    "    kl_div = 0.5 * kl_div\n",
    "    return kl_div\n",
    "\n",
    "def log_prob_sigma(value, loc, log_scale):\n",
    "    \"\"\"A slightly more stable (not confirmed yet) log prob taking in log_var instead of scale.\n",
    "    modified from https://github.com/pytorch/pytorch/blob/2431eac7c011afe42d4c22b8b3f46dedae65e7c0/torch/distributions/normal.py#L65\n",
    "    \"\"\"\n",
    "    var = torch.exp(log_scale * 2)\n",
    "    return (\n",
    "        -((value - loc) ** 2) / (2 * var) - log_scale - math.log(math.sqrt(2 * math.pi))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T03:19:33.064975Z",
     "start_time": "2020-02-01T03:19:33.036431Z"
    }
   },
   "outputs": [],
   "source": [
    "class LatentModel(nn.Module):\n",
    "    def __init__(self,\n",
    "                 x_dim,\n",
    "                 y_dim,\n",
    "                 hidden_dim=32,\n",
    "                 latent_dim=32,\n",
    "                 latent_enc_self_attn_type=\"dot\",\n",
    "                 det_enc_self_attn_type=\"dot\",\n",
    "                 det_enc_cross_attn_type=\"dot\",\n",
    "                 n_latent_encoder_layers=3,\n",
    "                 n_det_encoder_layers=3,\n",
    "                 n_decoder_layers=3,\n",
    "                 use_deterministic_path=True,\n",
    "                 min_std=0.01,\n",
    "                 use_lvar=False,\n",
    "                 attention_layers=2,\n",
    "                ):\n",
    "\n",
    "        super(LatentModel, self).__init__()\n",
    "\n",
    "        self._latent_encoder = LatentEncoder(\n",
    "            x_dim + y_dim,\n",
    "            hidden_dim=hidden_dim,\n",
    "            latent_dim=latent_dim,\n",
    "            self_attention_type=latent_enc_self_attn_type,\n",
    "            n_encoder_layers=n_latent_encoder_layers,\n",
    "            attention_layers=attention_layers)\n",
    "\n",
    "        self._deterministic_encoder = DeterministicEncoder(\n",
    "            input_dim=x_dim + y_dim,\n",
    "            x_dim=x_dim,\n",
    "            hidden_dim=hidden_dim,\n",
    "            self_attention_type=det_enc_self_attn_type,\n",
    "            cross_attention_type=det_enc_cross_attn_type,\n",
    "            n_d_encoder_layers=n_det_encoder_layers,\n",
    "            attention_layers=attention_layers)\n",
    "\n",
    "        self._decoder = Decoder(\n",
    "            x_dim,\n",
    "            y_dim,\n",
    "            hidden_dim=hidden_dim,\n",
    "            latent_dim=latent_dim,\n",
    "            min_std=min_std,\n",
    "            use_lvar=use_lvar,\n",
    "            n_decoder_layers=n_decoder_layers,\n",
    "            use_deterministic_path=use_deterministic_path,\n",
    "            \n",
    "        )\n",
    "        self._use_deterministic_path = use_deterministic_path\n",
    "        self._use_lvar = use_lvar\n",
    "\n",
    "    def forward(self, context_x, context_y, target_x, target_y=None):\n",
    "        num_targets = target_x.size(1)\n",
    "\n",
    "        dist_prior, log_var_prior = self._latent_encoder(context_x, context_y)\n",
    "\n",
    "        if target_y is not None:\n",
    "            dist_post, log_var_post = self._latent_encoder(target_x,\n",
    "                                                             target_y)\n",
    "            z = dist_post.loc\n",
    "        else:\n",
    "            z = dist_prior.loc\n",
    "\n",
    "        z = z.unsqueeze(1).repeat(1, num_targets, 1)  # [B, T_target, H]\n",
    "\n",
    "        if self._use_deterministic_path:\n",
    "            r = self._deterministic_encoder(context_x, context_y,\n",
    "                                            target_x)  # [B, T_target, H]\n",
    "        else:\n",
    "            r = None\n",
    "\n",
    "        dist, log_sigma = self._decoder(r, z, target_x)\n",
    "        if target_y is not None:\n",
    "            if self._use_lvar:\n",
    "                log_p = log_prob_sigma(target_y, dist.loc, log_sigma).mean(-1) # [B, T_target, Y].mean(-1)\n",
    "                kl_loss = kl_loss_var(dist_prior.loc, log_var_prior,\n",
    "                                      dist_post.loc, log_var_post).mean(-1) # [B, R].mean(-1)\n",
    "            else:\n",
    "                log_p = dist.log_prob(target_y).mean(-1)\n",
    "                kl_loss = torch.distributions.kl_divergence(\n",
    "                    dist_post, dist_prior).mean(-1)\n",
    "            kl_loss = kl_loss[:, None].expand(log_p.shape)\n",
    "            mse_loss = F.mse_loss(dist.loc, target_y)\n",
    "            loss = (kl_loss - log_p).mean()\n",
    "\n",
    "        else:\n",
    "            log_p = None\n",
    "            mse_loss = None\n",
    "            kl_loss = None\n",
    "            loss = None\n",
    "\n",
    "        y_pred = dist.rsample() if self.training else dist.loc\n",
    "        return y_pred, kl_loss, loss, mse_loss, dist.scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T03:19:33.080375Z",
     "start_time": "2020-02-01T03:19:33.067520Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_functions(target_x, target_y, context_x, context_y, pred_y, std):\n",
    "    \"\"\"Plots the predicted mean and variance and the context points.\n",
    "  \n",
    "  Args: \n",
    "    target_x: An array of shape [B,num_targets,1] that contains the\n",
    "        x values of the target points.\n",
    "    target_y: An array of shape [B,num_targets,1] that contains the\n",
    "        y values of the target points.\n",
    "    context_x: An array of shape [B,num_contexts,1] that contains \n",
    "        the x values of the context points.\n",
    "    context_y: An array of shape [B,num_contexts,1] that contains \n",
    "        the y values of the context points.\n",
    "    pred_y: An array of shape [B,num_targets,1] that contains the\n",
    "        predicted means of the y values at the target points in target_x.\n",
    "    std: An array of shape [B,num_targets,1] that contains the\n",
    "        predicted std dev of the y values at the target points in target_x.\n",
    "      \"\"\"\n",
    "    # Plot everything\n",
    "    plt.plot(target_x[0], pred_y[0], 'b', linewidth=2)\n",
    "    plt.plot(target_x[0], target_y[0], 'k:', linewidth=2)\n",
    "    plt.plot(context_x[0], context_y[0], 'ko', markersize=10)\n",
    "    plt.fill_between(\n",
    "          target_x[0, :, 0],\n",
    "          pred_y[0, :, 0] - std[0, :, 0],\n",
    "          pred_y[0, :, 0] + std[0, :, 0],\n",
    "          alpha=0.2,\n",
    "          facecolor='#65c9f7',\n",
    "          interpolate=True)\n",
    "\n",
    "    # Make the plot pretty\n",
    "    plt.yticks([-2, 0, 2], fontsize=16)\n",
    "    plt.xticks([-2, 0, 2], fontsize=16)\n",
    "    plt.ylim([-2, 2])\n",
    "    plt.grid('off')\n",
    "    ax = plt.gca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T03:19:33.099668Z",
     "start_time": "2020-02-01T03:19:33.083014Z"
    }
   },
   "outputs": [],
   "source": [
    "def test(model, dataset_test, writer=None, plot=False, global_step=None):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        data_test = dataset_test.generate_curves()\n",
    "\n",
    "        (context_x, context_y), target_x = data_test.query\n",
    "        target_y = data_test.target_y\n",
    "\n",
    "        context_x = context_x.cuda()\n",
    "        context_y = context_y.cuda()\n",
    "        target_x = target_x.cuda()\n",
    "        target_y = target_y.cuda()\n",
    "\n",
    "        y_pred, kl, loss, mse_loss, y_std = model(context_x, context_y, target_x, target_y)\n",
    "\n",
    "        if writer is not None:\n",
    "            writer.add_scalar('val/loss', loss, global_step=global_step)\n",
    "            writer.add_scalar('val/y_std', y_std.mean(), global_step=global_step)\n",
    "            writer.add_scalar('val/mse_loss', mse_loss, global_step=global_step)\n",
    "            writer.add_scalar('val/kl', kl.mean(), global_step=global_step)\n",
    "        \n",
    "        if plot:\n",
    "            fig = plt.figure()\n",
    "            plt.title(f\"Iter {n_iter}\")            \n",
    "            plot_functions(target_x.detach().cpu().numpy(),\n",
    "                           target_y.detach().cpu().numpy(),\n",
    "                           context_x.detach().cpu().numpy(),\n",
    "                           context_y.detach().cpu().numpy(),\n",
    "                           y_pred.detach().cpu().numpy(),\n",
    "                           y_std.detach().cpu().numpy())\n",
    "            \n",
    "            writer.add_figure('test', fig, global_step=global_step, close=False)\n",
    "            plt.show()\n",
    "            \n",
    "    return y_pred, kl, loss, y_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T03:19:33.119679Z",
     "start_time": "2020-02-01T03:19:33.101969Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs/Feb01_11-19-33_mjcdesktop-anp_1d_reg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "MAX_CONTEXT_POINTS = 50 \n",
    "random_kernel_parameters=True \n",
    "\n",
    "dataset_train = GPCurvesReader(\n",
    "    batch_size=16, max_num_context=MAX_CONTEXT_POINTS, random_kernel_parameters=random_kernel_parameters)\n",
    "\n",
    "dataset_test = GPCurvesReader(\n",
    "    batch_size=1, max_num_context=MAX_CONTEXT_POINTS, testing=True, random_kernel_parameters=random_kernel_parameters)\n",
    "\n",
    "writer = SummaryWriter(comment='-anp_1d_reg')\n",
    "print(writer.logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T03:19:33.175871Z",
     "start_time": "2020-02-01T03:19:33.122446Z"
    }
   },
   "outputs": [],
   "source": [
    "hparams = dict(x_dim=1, y_dim=1, hidden_dim=128, latent_dim=128, latent_enc_self_attn_type=\"multihead\", det_enc_self_attn_type=\"multihead\",\n",
    "                   det_enc_cross_attn_type=\"multihead\")\n",
    "model = LatentModel(**hparams).cuda()\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T01:23:02.658135Z",
     "start_time": "2020-02-01T01:23:02.653762Z"
    }
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-01T03:19:32.800Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c16408b24384de3bb64ec531aabba61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=100000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 0 loss= 0.9087 val_loss= 2.267\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 100000\n",
    "PLOT_AFTER = 10000\n",
    "PRINT_AFTER = 1000\n",
    "for n_iter in tqdm(range(epochs)):\n",
    "    model.train()\n",
    "    \n",
    "    data_train = dataset_train.generate_curves()\n",
    "    \n",
    "    (context_x, context_y), target_x = data_train.query\n",
    "    target_y = data_train.target_y\n",
    "    \n",
    "    context_x = context_x.cuda()\n",
    "    context_y = context_y.cuda()\n",
    "    target_x = target_x.cuda()\n",
    "    target_y = target_y.cuda()\n",
    "\n",
    "    optim.zero_grad()\n",
    "    y_pred, kl, loss, mse_loss, y_std = model(context_x, context_y, target_x, target_y)    \n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    \n",
    "    writer.add_scalar('train/loss', loss, n_iter)\n",
    "    writer.add_scalar('train/mse_loss', mse_loss, n_iter)\n",
    "    writer.add_scalar('train/y_std', y_std.mean(), n_iter)\n",
    "    writer.add_scalar('train/kl', kl.mean(), n_iter)\n",
    "    \n",
    "    if n_iter % PRINT_AFTER == 0:\n",
    "        y_pred, kl, val_loss, y_std = test(model, dataset_test, writer, plot=False, global_step=n_iter)\n",
    "        print(f\"train: {n_iter} loss={loss.item(): 4.4g} val_loss={val_loss.item(): 4.4g}\")\n",
    "\n",
    "    if n_iter % PLOT_AFTER == 0:\n",
    "        test(model, dataset_test, writer, plot=True, global_step=n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T03:19:26.014782Z",
     "start_time": "2020-02-01T03:11:00.300Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-01T03:19:32.800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Final validation\n",
    "loss = torch.stack([test(model, dataset_test)[2] for _ in tqdm(range(100))]).mean().cpu()\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-01T03:19:32.800Z"
    }
   },
   "outputs": [],
   "source": [
    "writer.add_hparams(hparams, dict(val_loss=loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jup3.7.2",
   "language": "python",
   "name": "jup3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
