{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T07:54:02.363236Z",
     "start_time": "2019-11-02T07:53:58.908538Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wassname/.pyenv/versions/3.7.2/envs/jup3.7.2/lib/python3.7/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['plt']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import collections\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import math\n",
    "%pylab inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T07:54:02.388602Z",
     "start_time": "2019-11-02T07:54:02.367207Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logger = logging.getLogger(\"smartmeters.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T07:54:04.083691Z",
     "start_time": "2019-11-02T07:54:02.393334Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T07:54:04.163614Z",
     "start_time": "2019-11-02T07:54:04.089048Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.models.model import LatentModel\n",
    "from src.data.smart_meter import collate_fns, SmartMeterDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T07:54:04.198056Z",
     "start_time": "2019-11-02T07:54:04.166801Z"
    }
   },
   "outputs": [],
   "source": [
    "# Params\n",
    "device='cuda'\n",
    "batch_size=32\n",
    "num_workers=5\n",
    "use_logy=False\n",
    "num_context, num_extra_target = 24*2*3, 24*2\n",
    "esp=1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load kaggle smart meter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T08:21:26.732814Z",
     "start_time": "2019-11-02T08:21:24.554630Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b879aef8172a45a38059eae39facb977",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1222670 entries, 0 to 1222669\n",
      "Data columns (total 3 columns):\n",
      "LCLid             1222670 non-null object\n",
      "tstp              1222670 non-null datetime64[ns]\n",
      "energy(kWh/hh)    1222620 non-null float64\n",
      "dtypes: datetime64[ns](1), float64(1), object(1)\n",
      "memory usage: 28.0+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>energy(kWh/hh)</th>\n",
       "      <th>tstp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-12-03 09:00:00</th>\n",
       "      <td>0.149</td>\n",
       "      <td>2011-12-03 09:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-03 09:30:00</th>\n",
       "      <td>0.154</td>\n",
       "      <td>2011-12-03 09:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-03 10:00:00</th>\n",
       "      <td>0.768</td>\n",
       "      <td>2011-12-03 10:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     energy(kWh/hh)                tstp\n",
       "                                                       \n",
       "2011-12-03 09:00:00           0.149 2011-12-03 09:00:00\n",
       "2011-12-03 09:30:00           0.154 2011-12-03 09:30:00\n",
       "2011-12-03 10:00:00           0.768 2011-12-03 10:00:00"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_files = sorted(Path('data/smart-meters-in-london/halfhourly_dataset').glob('*.csv'))[:1]\n",
    "df = pd.concat([pd.read_csv(f, parse_dates=[1], na_values=['Null']) for f in tqdm(csv_files)])\n",
    "print(df.info())\n",
    "\n",
    "df = df.groupby('tstp').mean()\n",
    "df['tstp'] = df.index\n",
    "df.index.name = ''\n",
    "df.head(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T08:21:26.926614Z",
     "start_time": "2019-11-02T08:21:26.735983Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39292\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "39225"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load weather data\n",
    "df_weather = pd.read_csv('data/smart-meters-in-london/weather_hourly_darksky.csv', parse_dates=[3])\n",
    "\n",
    "use_cols = ['visibility', 'windBearing', 'temperature', 'time', 'dewPoint',\n",
    "       'pressure', 'apparentTemperature', 'windSpeed', \n",
    "       'humidity']\n",
    "df_weather = df_weather[use_cols].set_index('time')\n",
    "\n",
    "# Resample to match energy data    \n",
    "df_weather = df_weather.resample('30T').ffill()\n",
    "\n",
    "# Normalise\n",
    "weather_norms=dict(mean={'visibility': 11.2,\n",
    " 'windBearing': 195.7,\n",
    " 'temperature': 10.5,\n",
    " 'dewPoint': 6.5,\n",
    " 'pressure': 1014.1,\n",
    " 'apparentTemperature': 9.2,\n",
    " 'windSpeed': 3.9,\n",
    " 'humidity': 0.8},\n",
    "std={'visibility': 3.1,\n",
    " 'windBearing': 90.6,\n",
    " 'temperature': 5.8,\n",
    " 'dewPoint': 5.0,\n",
    " 'pressure': 11.4,\n",
    " 'apparentTemperature': 6.9,\n",
    " 'windSpeed': 2.0,\n",
    " 'humidity': 0.1})\n",
    "\n",
    "for col in df_weather.columns:\n",
    "    df_weather[col] -= weather_norms['mean'][col]\n",
    "    df_weather[col] /= weather_norms['std'][col]\n",
    "\n",
    "    \n",
    "print(len(df))\n",
    "df = pd.concat([df, df_weather], 1).dropna()\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-02T08:21:25.200Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Also find bank holidays\n",
    "df_hols = pd.read_csv('./data/smart-meters-in-london/uk_bank_holidays.csv', parse_dates=[0])\n",
    "holidays = set(df_hols['Bank holidays'].dt.round('D'))\n",
    "\n",
    "df['holiday'] = df.tstp.apply(lambda dt:dt.floor('D') in holidays).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T08:21:18.252646Z",
     "start_time": "2019-11-02T08:21:18.222796Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-02T08:21:25.500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add time features\n",
    "time = df.tstp\n",
    "df[\"month\"] = time.dt.month / 12.0\n",
    "df['day'] = time.dt.day / 310.0\n",
    "df['week'] = time.dt.week / 52.0\n",
    "df['hour'] = time.dt.hour / 24.0\n",
    "df['dayofweek'] = time.dt.dayofweek / 7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-02T08:21:25.700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Drop nan and 0's\n",
    "df = df[df['energy(kWh/hh)']!=0]\n",
    "df = df.dropna()\n",
    "\n",
    "if use_logy:\n",
    "    df['energy(kWh/hh)'] = np.log(df['energy(kWh/hh)']+eps)\n",
    "df = df.sort_values('tstp')\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T05:00:36.615523Z",
     "start_time": "2019-11-02T05:00:36.538916Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-02T08:21:26.500Z"
    }
   },
   "outputs": [],
   "source": [
    "# split data\n",
    "n_split = -int(len(df)*0.1)\n",
    "df_train = df[:n_split]\n",
    "df_test = df[n_split:]\n",
    "len(df_train), len(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T05:35:58.304088Z",
     "start_time": "2019-11-02T05:35:58.274458Z"
    }
   },
   "source": [
    "# Plot helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-02T08:21:27.600Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_functions(target_x, target_y, context_x, context_y, pred_y, std, undo_log=use_logy):\n",
    "    \"\"\"Plots the predicted mean and variance and the context points.\n",
    "  \n",
    "  Args: \n",
    "    target_x: An array of shape [B,num_targets,1] that contains the\n",
    "        x values of the target points.\n",
    "    target_y: An array of shape [B,num_targets,1] that contains the\n",
    "        y values of the target points.\n",
    "    context_x: An array of shape [B,num_contexts,1] that contains \n",
    "        the x values of the context points.\n",
    "    context_y: An array of shape [B,num_contexts,1] that contains \n",
    "        the y values of the context points.\n",
    "    pred_y: An array of shape [B,num_targets,1] that contains the\n",
    "        predicted means of the y values at the target points in target_x.\n",
    "    std: An array of shape [B,num_targets,1] that contains the\n",
    "        predicted std dev of the y values at the target points in target_x.\n",
    "      \"\"\"\n",
    "    if undo_log:\n",
    "        target_y=np.exp(target_y)-eps\n",
    "        context_y=np.exp(context_y)-eps\n",
    "    # Plot everything \n",
    "    # Note: days is first feature in x, since we made sure of that in the dataloader)\n",
    "    j=0\n",
    "    \n",
    "    plt.plot(target_x[0,:,j], target_y[0], 'k:', linewidth=2, label='true')\n",
    "    plt.plot(context_x[0,:,j], context_y[0], 'ko', markersize=6, label='input data')\n",
    "    ylims=plt.ylim()\n",
    "    plt.plot(target_x[0,:,j], pred_y[0], 'b', linewidth=2, label='predicted')\n",
    "    plt.fill_between(\n",
    "          target_x[0, :, j],\n",
    "          pred_y[0, :, 0] - std[0, :, 0],\n",
    "          pred_y[0, :, 0] + std[0, :, 0],\n",
    "          alpha=0.5,\n",
    "          facecolor='#65c9f7',\n",
    "          interpolate=True,\n",
    "    label='uncertainty')\n",
    "\n",
    "    # Make the plot pretty\n",
    "    plt.ylim(*ylims)\n",
    "    plt.xlabel('Days')\n",
    "    plt.ylabel('Energy (kWh/hh)')\n",
    "    plt.grid('off')\n",
    "    plt.legend()\n",
    "    ax = plt.gca()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T07:51:32.547805Z",
     "start_time": "2019-11-02T07:51:32.247844Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-02T08:21:28.000Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_from_loader(loader, i=0, undo_log=use_logy, title='', plot=True):\n",
    "    data = loader.collate_fn([loader.dataset[i]])\n",
    "    data = [d.to(device) for d in data]\n",
    "    context_x, context_y, target_x, target_y = data\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred, kl, loss_test, y_std = model(context_x, context_y, target_x, target_y)\n",
    "\n",
    "        if plot:\n",
    "            plt.title(title+f\" loss={loss_test: 2.2g}\")\n",
    "            plot_functions(target_x.detach().cpu().numpy(),\n",
    "                            target_y.detach().cpu().numpy(),\n",
    "                            context_x.detach().cpu().numpy(),\n",
    "                            context_y.detach().cpu().numpy(),\n",
    "                            y_pred.detach().cpu().numpy(),\n",
    "                            y_std.detach().cpu().numpy(), undo_log=undo_log)\n",
    "    return loss_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T05:13:17.870138Z",
     "start_time": "2019-11-02T05:13:17.836065Z"
    }
   },
   "source": [
    "# Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-02T08:21:28.900Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train = SmartMeterDataSet(df_train, num_context, num_extra_target)\n",
    "data_test = SmartMeterDataSet(df_test, num_context, num_extra_target)\n",
    "data_test[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T05:19:43.988134Z",
     "start_time": "2019-11-02T05:19:43.959496Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-02T08:21:29.300Z"
    }
   },
   "outputs": [],
   "source": [
    "loader_train = torch.utils.data.DataLoader(data_train, batch_size=batch_size, shuffle=True, \n",
    "    collate_fn=collate_fns(num_context, num_extra_target, sample=True),\n",
    "    num_workers=num_workers,\n",
    ")\n",
    "\n",
    "loader_test = torch.utils.data.DataLoader(data_test, batch_size=batch_size, shuffle=False, \n",
    "    collate_fn=collate_fns(num_context, num_extra_target, sample=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-02T08:21:29.700Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x, y, _, _ = next(iter(loader_train))\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-02T08:21:29.900Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.models.model import LatentModel\n",
    "model = LatentModel(\n",
    "    x_dim=x.shape[-1], \n",
    "    y_dim=y.shape[-1], \n",
    "    hidden_dim=128, \n",
    "    latent_dim=128,\n",
    "    dropout=0.5,\n",
    "    num_heads=8,\n",
    "    n_latent_encoder_layers=8,\n",
    "    n_det_encoder_layers=8,\n",
    "    n_decoder_layers=6,\n",
    "    latent_enc_self_attn_type=\"multihead\", \n",
    "    det_enc_self_attn_type=\"multihead\",\n",
    "    det_enc_cross_attn_type=\"multihead\").to(device)\n",
    "\n",
    "optim = torch.optim.AdamW(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-02T08:21:31.900Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchsummaryX import summary\n",
    "data = next(iter(loader_train))\n",
    "data = [d.to(device) for d in data]\n",
    "context_x, context_y, target_x, target_y = data\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    summary(model, context_x, context_y, target_x, target_y)\n",
    "    dist, log_p, kl, loss = model(context_x, context_y, target_x, target_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-02T08:21:32.100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Lets choose a challenging time to forecast\n",
    "vis_i = 690 # 290 # 1600\n",
    "plot_from_loader(loader_test, i=690)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-02T08:21:32.200Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "grad_clip = 10\n",
    "history = []\n",
    "for epoch in tqdm(range(epochs), unit='epoch'):\n",
    "\n",
    "    pbar = tqdm(loader_train, unit='batch')\n",
    "    for i, data in enumerate(pbar):\n",
    "        model.train()\n",
    "        assert all(torch.isfinite(d).all() for d in data)\n",
    "        data = [d.to(device) for d in data]\n",
    "        context_x, context_y, target_x, target_y = data\n",
    "\n",
    "        optim.zero_grad()\n",
    "        y_pred, kl, loss, y_std = model(context_x, context_y, target_x, target_y)\n",
    "\n",
    "        # These attentive NP models work great when you need uncertainty, but still seem a bit unstable. \n",
    "        # Sometimes they produce nans, especically if the data is not fully normalized. \n",
    "        assert torch.isfinite(y_pred.sum())\n",
    "        if not torch.isfinite(loss):\n",
    "            logger.error(\"loss is not finite\")\n",
    "            continue\n",
    "        loss.backward()\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "        if not np.isfinite(grad_norm):\n",
    "            logger.error(\"grad_norm is not finite\")\n",
    "            continue\n",
    "        optim.step()\n",
    "\n",
    "        if i%300==0:\n",
    "            model.eval()\n",
    "            test_loss = plot_from_loader(loader_test, i=vis_i, plot=False)\n",
    "            pbar.set_description(f\"{epoch}, loss: {loss.item():4.4g}, test: {test_loss.item():4.4g}\")\n",
    "            print(f\"{epoch}, i={i}, loss: {loss.item():4.4g}, test: {test_loss.item():4.4g}, grad_norm: {grad_norm: 2.2g}, std: {y_std.mean().item(): 2.2g}\")\n",
    "            \n",
    "            history.append(dict(\n",
    "                n=epoch*len(loader_train) + i,\n",
    "                epoch=epoch,\n",
    "                i=i,\n",
    "                loss=loss.item(),\n",
    "                kl=kl.mean().item(),\n",
    "                test_loss=test_loss.item(),\n",
    "                y_std=y_std.mean().item(),\n",
    "                grad_norm=grad_norm,\n",
    "            ))\n",
    "        \n",
    "    test_loss = plot_from_loader(loader_train, i=vis_i, title=f'epoch={epoch}, train,')\n",
    "    model.eval()\n",
    "    test_loss = plot_from_loader(loader_test, i=vis_i, title=f'epoch={epoch}, test,')\n",
    "    print(f\"epoch: {epoch}, loss: {loss.item():4.4g}, loss_test:{test_loss.item():4.4g}, kl={kl.mean().item()}, grad_norm: {grad_norm: 2.2g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-02T08:21:32.400Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_from_loader(loader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-02T08:21:32.500Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_from_loader(loader_train, undo_log=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-02T08:21:32.900Z"
    }
   },
   "outputs": [],
   "source": [
    "df_hist = pd.DataFrame(history)\n",
    "df_hist['n'] = df_hist['n']/(df_hist['epoch']+1)\n",
    "df_hist = df_hist.set_index('n')\n",
    "df_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-02T08:21:33.000Z"
    }
   },
   "outputs": [],
   "source": [
    "df_hist[['loss', 'test_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T07:30:43.274252Z",
     "start_time": "2019-11-02T07:30:42.147116Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "jup3.7.2",
   "language": "python",
   "name": "jup3.7.2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
