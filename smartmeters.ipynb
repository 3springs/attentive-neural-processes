{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   }
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Populating the interactive namespace from numpy and matplotlib\n/home/wassname/.pyenv/versions/jup3.7.2/lib/python3.7/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['plt']\n`%matplotlib` prevents importing * from pylab and numpy\n  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import collections\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "import math\n",
    "%pylab inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logger = logging.getLogger(\"smartmeters.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.model import LatentModel\n",
    "from src.data.smart_meter import collate_fns, SmartMeterDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params\n",
    "device='cuda'\n",
    "batch_size=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "100%|██████████| 2/2 [00:04<00:00,  1.96s/it]<class 'pandas.core.frame.DataFrame'>\nInt64Index: 2738535 entries, 0 to 1515864\nData columns (total 3 columns):\nLCLid             object\ntstp              datetime64[ns]\nenergy(kWh/hh)    float64\ndtypes: datetime64[ns](1), float64(1), object(1)\nmemory usage: 83.6+ MB\nNone\n\n"
    },
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LCLid</th>\n      <th>tstp</th>\n      <th>energy(kWh/hh)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>MAC000002</td>\n      <td>2012-10-12 00:30:00</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>MAC000002</td>\n      <td>2012-10-12 01:00:00</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>MAC000002</td>\n      <td>2012-10-12 01:30:00</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "       LCLid                tstp  energy(kWh/hh)\n0  MAC000002 2012-10-12 00:30:00             0.0\n1  MAC000002 2012-10-12 01:00:00             0.0\n2  MAC000002 2012-10-12 01:30:00             0.0"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_files = sorted(Path('data/smart-meters-in-london/halfhourly_dataset').glob('*.csv'))[:2]\n",
    "df = pd.concat([pd.read_csv(f, parse_dates=[1], na_values=['Null']) for f in tqdm(csv_files)])\n",
    "print(df.info())\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>energy(kWh/hh)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>39247.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>-1.510907</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.127931</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-9.210340</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>-2.291645</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>-1.569737</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>-0.737935</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.948493</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "       energy(kWh/hh)\ncount    39247.000000\nmean        -1.510907\nstd          1.127931\nmin         -9.210340\n25%         -2.291645\n50%         -1.569737\n75%         -0.737935\nmax          1.948493"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df['energy(kWh/hh)'] = df['energy(kWh/hh)'].replace('Null', np.nan)\n",
    "df = df[['tstp', 'energy(kWh/hh)']].dropna()\n",
    "eps = 1e-4\n",
    "df['energy(kWh/hh)'] = np.log(df['energy(kWh/hh)']+eps)\n",
    "# df['tstp'] = pd.to_datetime(df['tstp'])\n",
    "# df['energy(kWh/hh)'] = pd.to_numeric(df['energy(kWh/hh)'])\n",
    "df = df.sort_values('tstp')\n",
    "df = df.drop_duplicates(subset=['tstp'])\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(35323, 3924)"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_split = -int(len(df)*0.1)\n",
    "df_train = df[:n_split]\n",
    "df_test = df[n_split:]\n",
    "len(df_train), len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_functions(target_x, target_y, context_x, context_y, pred_y, std):\n",
    "    \"\"\"Plots the predicted mean and variance and the context points.\n",
    "  \n",
    "  Args: \n",
    "    target_x: An array of shape [B,num_targets,1] that contains the\n",
    "        x values of the target points.\n",
    "    target_y: An array of shape [B,num_targets,1] that contains the\n",
    "        y values of the target points.\n",
    "    context_x: An array of shape [B,num_contexts,1] that contains \n",
    "        the x values of the context points.\n",
    "    context_y: An array of shape [B,num_contexts,1] that contains \n",
    "        the y values of the context points.\n",
    "    pred_y: An array of shape [B,num_targets,1] that contains the\n",
    "        predicted means of the y values at the target points in target_x.\n",
    "    std: An array of shape [B,num_targets,1] that contains the\n",
    "        predicted std dev of the y values at the target points in target_x.\n",
    "      \"\"\"\n",
    "  # Plot everything\n",
    "    plt.plot(target_x[0], pred_y[0], 'b', linewidth=2)\n",
    "    plt.plot(target_x[0], target_y[0], 'k:', linewidth=2)\n",
    "    plt.plot(context_x[0], context_y[0], 'ko', markersize=10)\n",
    "    plt.fill_between(\n",
    "          target_x[0, :, 0],\n",
    "          pred_y[0, :, 0] - std[0, :, 0],\n",
    "          pred_y[0, :, 0] + std[0, :, 0],\n",
    "          alpha=0.5,\n",
    "          facecolor='#65c9f7',\n",
    "          interpolate=True)\n",
    "\n",
    "    # Make the plot pretty\n",
    "    plt.ylim([context_y.min()-2, context_y.max()+2])\n",
    "    plt.grid('off')\n",
    "    ax = plt.gca()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_context, num_extra_target = 40, 10\n",
    "data_train = SmartMeterDataSet(df_train, num_context, num_extra_target)\n",
    "data_test = SmartMeterDataSet(df_test, num_context, num_extra_target)\n",
    "# data_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_train = torch.utils.data.DataLoader(data_train, batch_size=batch_size, shuffle=True, \n",
    "    collate_fn=collate_fns(num_context, num_extra_target, sample=True)\n",
    ")\n",
    "\n",
    "loader_test = torch.utils.data.DataLoader(data_test, batch_size=batch_size, shuffle=False, \n",
    "    collate_fn=collate_fns(num_context, num_extra_target, sample=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([16, 19, 1]), torch.Size([16, 19, 1]), tensor([[0.0000],\n         [0.0417],\n         [0.0625],\n         [0.1458],\n         [0.1875],\n         [0.2083],\n         [0.2708],\n         [0.2917],\n         [0.3125],\n         [0.4167],\n         [0.4375],\n         [0.4792],\n         [0.6250],\n         [0.6458],\n         [0.6875],\n         [0.7083],\n         [0.7292],\n         [0.7500],\n         [0.7917]]), tensor([[-1.8382],\n         [-1.8382],\n         [-0.9111],\n         [-0.1472],\n         [-2.4068],\n         [-1.7773],\n         [-3.0769],\n         [-0.6990],\n         [-2.6023],\n         [-1.2655],\n         [-1.3899],\n         [-2.5757],\n         [-1.9944],\n         [-2.9169],\n         [-1.4435],\n         [-2.0707],\n         [-2.1707],\n         [-2.2818],\n         [-2.0318]]))"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y, _, _ = next(iter(loader_train))\n",
    "x.shape, y.shape, x[0], y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.models.model import LatentModel\n",
    "model = LatentModel(\n",
    "    x_dim=x.shape[-1], \n",
    "    y_dim=y.shape[-1], \n",
    "    hidden_dim=32, \n",
    "    latent_dim=32,\n",
    "    dropout=0,\n",
    "    num_heads=4,\n",
    "    n_latent_encoder_layers=3,\n",
    "    n_det_encoder_layers=3,\n",
    "    n_decoder_layers=3,\n",
    "    latent_enc_self_attn_type=\"multihead\", \n",
    "    det_enc_self_attn_type=\"multihead\",\n",
    "    det_enc_cross_attn_type=\"multihead\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.AdamW(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "epochs:   0%|          | 0/100 [00:00<?, ?it/s]\nTraining:   0%|          | 0/2205 [00:00<?, ?it/s]\u001b[Atrain: 0, 0/2205, loss: 50.16, grad_norm:  2.6e+02\ntrain: 0, 100/2205, loss: 33.41, grad_norm:  2.4e+02\ntrain: 0, 200/2205, loss: 21.67, grad_norm:  1.4e+02\ntrain: 0, 300/2205, loss: 13.5, grad_norm:  39\n\nTraining:  17%|█▋        | 376/2205 [01:00<04:52,  6.25it/s]\u001b[Atrain: 0, 400/2205, loss: 10.09, grad_norm:  78\n\nTraining:  17%|█▋        | 376/2205 [01:20<04:52,  6.25it/s]\u001b[Atrain: 0, 500/2205, loss: 10.32, grad_norm:  79\n"
    }
   ],
   "source": [
    "epochs = 100\n",
    "grad_clip = 10\n",
    "for epoch in tqdm(range(epochs), desc='epochs'):\n",
    "    model.train()\n",
    "    for i, data in enumerate(tqdm(loader_train, mininterval=60, desc='Training')):\n",
    "        assert all(torch.isfinite(d).all() for d in data)\n",
    "        data = [d.to(device) for d in data]\n",
    "        context_x, context_y, target_x, target_y = data\n",
    "\n",
    "        optim.zero_grad()\n",
    "        y_pred, kl, loss, y_std = model(context_x, context_y, target_x, target_y)\n",
    "        assert torch.isfinite(y_pred.sum())\n",
    "        if not torch.isfinite(loss):\n",
    "            logger.error(\"loss is not finite\")\n",
    "            continue\n",
    "        loss.backward()\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "        if not np.isfinite(grad_norm):\n",
    "            logger.error(\"grad_norm is not finite\")\n",
    "            continue\n",
    "        optim.step()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(f\"train: {epoch}, {i}/{len(loader_train)}, loss: {loss.item():4.4g}, grad_norm: {grad_norm: 2.2g}\")\n",
    "    \n",
    "    for i, data in enumerate(tqdm(loader_test, mininterval=60, desc='Testing')):\n",
    "        data = [d.to(device) for d in data]\n",
    "        context_x, context_y, target_x, target_y = data\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_pred, kl, loss_test, y_std = model(context_x, context_y, target_x)\n",
    "            \n",
    "            plt.title(f\"epoch {epoch}\")\n",
    "            plot_functions(target_x.detach().cpu().numpy(),\n",
    "                           target_y.detach().cpu().numpy(),\n",
    "                           context_x.detach().cpu().numpy(),\n",
    "                           context_y.detach().cpu().numpy(),\n",
    "                           y_pred.detach().cpu().numpy(),\n",
    "                           y_std.detach().cpu().numpy())\n",
    "    print(f\"epoch: {epoch}, loss: {loss.item():4.4g}, loss_test:{loss_test.item():4.4g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}